A robust RESTful backend built with Node.js, Express, and PostgreSQL, powering the AI Experimentation Dashboard.
It handles experiment creation, retrieval, and data persistence for AI-generated results, ensuring scalable and consistent performance.

ğŸ—ï¸ Architecture Overview
llm-backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts          # Entry point
â”‚   â”œâ”€â”€ routes/           # Express routes
â”‚   â”œâ”€â”€ controllers/      # Route logic and handlers
â”‚   â”œâ”€â”€ services/         # Business logic / AI integration layer
â”‚   â”œâ”€â”€ models/           # Database models or Prisma schema
â”‚   â””â”€â”€ utils/            # Helpers and config
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ .env

âš™ï¸ Tech Stack
Layer	Technology
Runtime	Node.js (v18+)
Framework	Express.js
Language	TypeScript
Database	PostgreSQL 17
ORM / Client	Prisma
Deployment	Render
Logging & Error Handling	Custom middleware + console-based logs
ğŸš€ Features

âœ… Create AI experiments dynamically via REST API
âœ… Persist prompts, responses, and evaluation metrics in PostgreSQL
âœ… Fetch and visualize experiment data via frontend
âœ… Clean modular structure following MVC principles
âœ… Strong typing with TypeScript
âœ… Ready for horizontal scaling and cloud deployment

ğŸ“¦ Installation

Clone the backend repository:

git clone https://github.com/<your-username>/llm-backend.git
cd llm-backend


Install dependencies:

npm install

ğŸ” Environment Variables

Create a .env file in the root of the project and include:

DATABASE_URL=postgresql://<user>:<password>@<host>:<port>/<database>
PORT=5000
NODE_ENV=development


If using Prisma, run migrations:

npx prisma migrate dev

ğŸ§  Scripts
Command	Description
npm run dev	Run in development with Nodemon
npm run build	Compile TypeScript into dist/
npm start	Start compiled production server
ğŸ“¡ API Endpoints
Method	Endpoint	Description
GET	/api/experiments	Fetch all experiments
POST	/api/generate-experiment	Create and store a new experiment
GET	/api/db-check	Verify database connection

Example:

POST /api/generate-experiment

{
  "prompt": "What are ethical considerations in AI deployment?",
  "parameters": { "temperature": [0.7], "topP": [0.9] }
}


Response:

{
  "id": 42,
  "prompt": "What are ethical considerations in AI deployment?",
  "results": "[{\"response\": \"AI ethics include...\"}]",
  "createdAt": "2025-10-21T12:00:00Z"
}

 Development Notes

Uses TypeScript strict mode for better type safety.

All responses are JSON-formatted and versioned under /api/*.

Database layer separated from route logic for clean maintainability.

Logs are color-coded and structured for production observability.

Health check route available: /api/db-check.

â˜ï¸ Deployment

Deployed automatically via Render with PostgreSQL add-on.
Ensure environment variables are configured under Render Dashboard â†’ Environment.

Backend URL:
https://llm-qou7.onrender.com

ğŸ§‘â€ğŸ’» Author

Benjamin Mwangi
Senior Software Engineer / AI Systems Developer
ğŸ“§ mwangib297@gmail.com
ğŸŒhttps://github.com/Benjamwas
